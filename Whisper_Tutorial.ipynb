{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/keatonkraiger/Whisper-Transcription-Tutorial/blob/main/Whisper_Tutorial.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "<a target=\"_blank\" href=\"https://youtu.be/i4Sgg-ptRzs\">\n",
        "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/e/ef/Youtube_logo.png\" alt=\"Tutorial Video\" width=\"24\" height=\"24\"/>\n",
        "</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Click the above button to open this notebook in Google Colab. \n",
        "- We recommend then making a copy of the notebook to your Google Drive so you can save your work (File -> Save a copy in Drive).\n",
        "- You may also view the accompanying supplamentary tutorial video [here](https://youtu.be/i4Sgg-ptRzs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elZFueXpoBeX"
      },
      "source": [
        "# Using OpenAI's Whisper\n",
        "OpenAI's Whisper is a general-purpose speech recognition model described in their 2022 [paper](https://arxiv.org/abs/2212.04356). This notebook is a practical introduction on how to use Whisper in Google Colab.\n",
        "\n",
        "Before diving into Whisper, it's important to set up your environment correctly. This guide will walk you through the process, ensuring that even if you're not technically inclined, you'll be able to use Whisper effectively. Note that you don't need to run Whisper in Colab, we are using it here for convenience and the ability to run the model on a GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6sNXKTPrwOH"
      },
      "source": [
        "## Setting Up Google Colab\n",
        "Google Colab provides a convenient platform to run Python code in the cloud, with access to powerful computing resources, including GPUs. To ensure your Colab notebook runs smoothly, it's recommended to enable GPU acceleration which will speed up your transcription. Note however that a GPU is not strictly necessary to use Whisper. Here's how you can enable it on Colab:\n",
        "\n",
        "\n",
        "1.   Click on 'Runtime' in the top menu.\n",
        "2.   Select 'Change runtime type'.\n",
        "3.   In the dialog that appears, under 'Hardware accelerator', choose 'GPU' (the type doesn't matter so much right now)\n",
        "4.   Click 'Save'.\n",
        "\n",
        "By enabling the GPU, your notebook will run more efficiently, especially when dealing with large models like Whisper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPIwL68B5EsB"
      },
      "source": [
        "We can also see the size of our GPU's VRAM with the `!nvidia-smi` command in order to see how large of a model we can use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DQxLKla4udR"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CooNwKbm5GE-"
      },
      "source": [
        "### Important Note\n",
        "\n",
        "In the following cells, you will often see an `!` symbol before the text/commands. This is because Colab cells expect *code*.\n",
        "\n",
        "By using `!`, we are telling Colab we typing a command instead of a piece of code! If you did not include a `!`, Colab would assume you are running (Python) code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMQgCyH25erR"
      },
      "outputs": [],
      "source": [
        "print('Hello world!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf_ZMeiPsN6t"
      },
      "source": [
        "## Getting Started with Whisper\n",
        "\n",
        "Whisper is available through OpenAI's GitHub repository. To use Whisper, you need to install it along with its dependencies. This guide will take you through the process step-by-step, ensuring a smooth setup. You may follow along in parallel looking at the Github as well! First, to install Whisper:\n",
        "\n",
        "\n",
        "\n",
        "1.   **Install Whisper**: Run the command !pip install -U openai-whisper in a Colab cell to install the latest release of Whisper.\n",
        "2.   **Install FFMPEG**: Whisper requires FFMPEG for audio processing. Use the command !apt install ffmpeg in Colab to install it.\n",
        "3.   **Additional Dependencies:** In some cases, you might need additional dependencies like setuptools-rust. If you encounter any installation errors, run !pip install setuptools-rust.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNWPxmUatKR8"
      },
      "outputs": [],
      "source": [
        "!pip install -U openai-whisper\n",
        "!apt install ffmpeg\n",
        "!pip install setuptools-rust"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s61zPEmsq68"
      },
      "source": [
        "## Available Models\n",
        "\n",
        "Whisper comes with several models, each offering a trade-off between speed and accuracy. Depending on your task, you can choose the model that best fits your needs. Importantly, the *size* of the model (Required VRAM) will be dictated by the GPU running the code **if** you are using a GPU.\n",
        "\n",
        "In this case, we will use the *medium* sized model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSRbuM-_tzMG"
      },
      "source": [
        "## Get your audio file ready!\n",
        "\n",
        "Of course, our goal is to transcripe an audio file. Thus, we will need to upload our file to colab. This can be achieved through\n",
        "\n",
        "1. Clicking the folder icon on the left sidebar at the bottom.\n",
        "2. Clicking the upload file button or dragging and dropping your file into the left side bar.\n",
        "\n",
        "**Be aware**: <ins>Colab sessions *will not* save files that have been uploaded or created. Be sure to save files that are created during sessions before exiting them.</ins>\n",
        "\n",
        "**File Upload**: in the case you are uploading large files, you may instead want to mount your Google Drive to colab. You can then move files from Drive into Colab, which is often faster than uploading them individually. This can be achieved by clicking the Mount Drive button at the top left sidebar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9_Vy_EDtdEU"
      },
      "source": [
        "## Using Whisper\n",
        "\n",
        "Once again, following the Github documentation, we can run Whisper through command-line arguments.\n",
        "\n",
        "Let's first test whisper through the `whisper --help` command-line argument:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REBmx_ALvcM4"
      },
      "outputs": [],
      "source": [
        "!whisper --help"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhFGoWkGvobg"
      },
      "source": [
        "The above help command lists command-line arguments we can use. Most will be unnecessary for our case, while some may be more applicable such as `--output_format` or `--language`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCVul2DHvYkg"
      },
      "source": [
        "Let's now try and transcribe an audio file! The following command will transcribe speech in audio file `Audio File.mp3`. We will use the arguments\n",
        "\n",
        "1.   `--model medium`: specify the model size\n",
        "2.   `--task transcribe`: to do transcription\n",
        "3.   `--output_dir transcription`: to save the files in the directory transcription\n",
        "4.   `--output_format all`: give transcription in all formats. Otherwise, you may select the one your prefer.\n",
        "\n",
        "Some caveats\n",
        "\n",
        "\n",
        "*   If you are running this without a GPU, you should include: `--device cpu`\n",
        "*   If you're input file is not in English, you can specify language with: `--language x` where x is the language in the audio file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We must specify the location of the audio file. In this case it's in `/content/AllStar.mp3`. We can determine this by rightclicking the audiofile and Copying the Path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdyQ2pyAn_Bd"
      },
      "outputs": [],
      "source": [
        "!whisper /content/AllStar.mp3 --model medium --task transcribe --output_dir transcription --output_format all --device cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqTQIgOPyEmk"
      },
      "source": [
        "Once the cell has completed, we can download the transcription files that are saved to the `transcription` directory. \n",
        "\n",
        "Colab doesn't allow you to download entire directories so we can instead `zip` it and download the zip file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFBt8cHZyRKq"
      },
      "outputs": [],
      "source": [
        "!zip -r transcriptions.zip transcription"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmRHI2u0yf-O"
      },
      "source": [
        "## Helpful Commands\n",
        "\n",
        "\n",
        "\n",
        "*   Often, you fill note want the transcription in every format. It may instead be better to select the most usable one for your case and just use that as the `--output_format`\n",
        "*   You can do multiple audio files at a time. You would do the same command, but include two or more audio files (e.g. `!whisper audio1.mp3 audio2.mp3 ...`)\n",
        "* Whisper may also be used for translation by setting `--task translate`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD3RbYIgzAR5"
      },
      "source": [
        "## Closing Remarks\n",
        "\n",
        "Using Whisper in Colab is convenient because it allows you to utilize a GPU for free! However, you can also use Whisper without a GPU on your local computer. To do this, you should follow the steps in Whisper's [Github Setup](https://github.com/openai/whisper#setup). If you choose to do so, some considerations\n",
        "\n",
        "\n",
        "\n",
        "1.   You will need to install Python to run whisper. This can be done in your terminal by first installing [brew](https://docs.brew.sh/Installation) with the command `/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"`. We recommend following `HomeBrew's [installation instructions.](https://brew.sh/) or this [guide](https://docs.python-guide.org/starting/install3/osx/).\n",
        "2.   Assuming brew is installed, you can install python with running `brew install python` inside your terminal.\n",
        "3.   With Python and brew installed, we recommend making a directory to work in. Inside your terminal, move to your desktop and create a directory: `cd Desktop; mkdir Whisper; cd Whisper`.\n",
        "\n",
        "Note: if you do wish to work on your personal macbook and do install brew, you will need to also install `Xcode` tools. If given the option, we recommend instead installing `Command Line Tools` as it is a much smaller package.\n",
        "\n",
        "Finally, while this document is primarily for mac users, the installation will be very similar across platforms. See Whisper's Github for more information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2X3ZBlF3xkr"
      },
      "source": [
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "</head>\n",
        "<body>\n",
        "     <img src=\"https://media.istockphoto.com/id/1294688589/photo/red-cat-with-blurred-the-poster-in-the-frame-with-the-words-thank-you.jpg?s=612x612&w=0&k=20&c=T84nHSu52sOQvrmnksdDNo2UByqJ7yXn1srkuodXdps=\" alt=\"Page Image\">\n",
        "    <br>\n",
        "</body>\n",
        "</html>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
